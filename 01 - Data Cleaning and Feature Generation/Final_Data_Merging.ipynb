{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ufoRfrOUv0Gt"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VMwqdltX0PN9"},"outputs":[],"source":["### Make a State-Level Mean Imputation Function\n","def impute_mean(df, col_to_impute):\n","  col_to_impute = str(col_to_impute)\n","  avg_col_name = str('avg_' + col_to_impute)\n","\n","  # Test to see if column is a binary variable\n","  binary_var = True if np.max(df[col_to_impute]) == 1 and np.min(df[col_to_impute]) == 0 else False\n","\n","  state_avg_df = df[['StateName', col_to_impute]]\n","  state_avg_df = state_avg_df.groupby('StateName').mean()\n","  state_avg_df.reset_index(inplace=True)\n","  state_avg_df.rename(columns={col_to_impute:avg_col_name}, inplace=True)\n","\n","  # If the column is binary, round to 1 or 0, and fill with 0 if null\n","  if binary_var:\n","    state_avg_df[avg_col_name] = np.round(state_avg_df[avg_col_name])\n","    state_avg_df[avg_col_name].fillna(0, inplace=True)\n","\n","  # Merge state-level average column to dataframe\n","  interim_df = df.copy()\n","  interim_df = interim_df.merge(right=state_avg_df, on='StateName', how='left', copy=False)\n","\n","  # Fill NAs with State-Level Means\n","  interim_df[col_to_impute] = np.where(interim_df[col_to_impute].isnull(), \n","                                       interim_df[avg_col_name], \n","                                       interim_df[col_to_impute])\n","  # If any NAs are leftover, fill them with the mean of the column\n","  interim_df[col_to_impute] = np.where(interim_df[col_to_impute].isnull(),\n","                                       np.nanmean(interim_df[col_to_impute]),\n","                                       interim_df[col_to_impute])\n","  interim_df.drop(columns=avg_col_name, inplace=True)\n","  df = interim_df.copy()\n","  return df[col_to_impute]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["honey_df = pd.read_csv('../04 - Data/Final Data/honey_neonic_cleaned.csv', index_col=0)\n","aphis_df = pd.read_csv('../04 - Data/Final Data/aphis_clean.csv', index_col=0)\n","temp_df = pd.read_csv('../04 - Data/Final Data/temperature.csv', index_col=0)\n","urb_df = pd.read_csv('../04 - Data/Final Data/urb_by_state-year.csv', index_col=0)\n","aq_df = pd.read_csv('../04 - Data/Final Data/aq_features.csv', index_col=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ehzLkQx6wRZ5"},"outputs":[],"source":["df = honey_df.merge(right=temp_df, left_on=['StateName', 'year'], right_on=['state', 'year'], how='left')\n","df.drop(columns=['state', 'code'], inplace=True)\n","merged_df = df.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Br5Zeh6px65A"},"outputs":[],"source":["df = merged_df.merge(right=aphis_df, left_on=['StateName', 'year'], right_on=['state', 'year'], how='left')\n","df.drop(columns=['state', 'code'], inplace=True)\n","merged_df = df.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TJS0L8beExPh"},"outputs":[],"source":["df = merged_df.merge(right=urb_df, left_on=['StateName', 'year'], right_on=['state', 'year'], how='left')\n","df.drop(columns=['state'], inplace=True)\n","merged_df = df.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MgPcRwqWEyFB"},"outputs":[],"source":["df = merged_df.merge(right=aq_df, left_on=['StateName', 'year'], right_on=['State', 'Year'], how='left')\n","df.drop(columns=['State', 'Year'], inplace=True)\n","merged_df = df.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oAEVs0MHdrky"},"outputs":[],"source":["cols_to_impute = [i for i in merged_df.columns if\n","    (merged_df[str(i)].dtype == 'float64' or \n","    merged_df[str(i)].dtype == 'int64') and\n","    merged_df[str(i)].count() < 825]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n6Bz5hv9fpRr"},"outputs":[],"source":["imputed_df = merged_df.copy()\n","for col in cols_to_impute:\n","  imputed_df[col] = impute_mean(imputed_df, col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8DPP7Jmvde0M"},"outputs":[],"source":["final_data_dummies = pd.get_dummies(imputed_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eUOkCNp4dCcg"},"outputs":[],"source":["final_data_dummies_minus1_col = pd.get_dummies(imputed_df, drop_first=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WdeTReIXGjlc"},"outputs":[],"source":["final_data_dummies.to_csv('../04 - Data/Final Data/final_data_dummies.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"puo28mOH83hR"},"outputs":[],"source":["final_data_dummies_minus1_col.to_csv(\n","    '../04 - Data/Final Data/final_data_dummies_minus1_col.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yinDgBqdGolM"},"outputs":[],"source":["imputed_df.to_csv('../04 - Data/Final Data/final_data.csv', index=False)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.8.2 ('base')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.2"},"vscode":{"interpreter":{"hash":"1a10f2fbefaf991ce5ca69099618177d9151aad1b2bddd9d8483fe14475f193e"}}},"nbformat":4,"nbformat_minor":0}
